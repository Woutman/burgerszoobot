import os

from dotenv import load_dotenv
import chromadb
import chromadb.utils.embedding_functions as embedding_functions
from chromadb.api.types import Metadata
from chromadb.db.base import UniqueConstraintError

from .llm_instructions import INSTRUCTIONS_EXAMPLE_ANSWER
from .llm_interface import query_gpt

BASE_DIR = os.path.dirname(os.path.abspath(__file__))
path_to_chromadb = os.path.join(BASE_DIR, 'chromadb')
client = chromadb.PersistentClient(path=path_to_chromadb)

load_dotenv("api_keys.env")
OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')
openai_embedding_function = embedding_functions.OpenAIEmbeddingFunction(
    api_key=OPENAI_API_KEY,
    model_name="text-embedding-3-small"
)

try:
    collection = client.create_collection(name="zoo_documents", embedding_function=openai_embedding_function)
except UniqueConstraintError:
    collection = client.get_collection(name="zoo_documents", embedding_function=openai_embedding_function)


def ingest_document(document_id: str, document_text: str, metadata: Metadata = None) -> None:
    print(f"ingesting document {document_id}.")
    collection.add(
        ids=[document_id],
        documents=[document_text],
        metadatas=[metadata]
    )


def delete_document(document_id: str) -> None:
    collection.delete(ids=[document_id])


def retrieve_documents(query_text: str, n_results: int) -> list[str]:
    '''
    Basic retrieval function.
    '''
    results = collection.query(query_texts=query_text, n_results=n_results)

    documents = results['documents'][0]

    return documents


def retrieve_documents_with_example_answer(query_text: str, n_results: int) -> list[str]:
    '''
    Retrieves documents based on user query, combined with an example answer generated by an LLM. 
    This answer doesn't need to be factually correct, but its structure and contents can assist with retrieval of documents.
    '''
    augmented_query = _augment_query_with_example_answer(query_text=query_text)
    
    results = collection.query(query_texts=augmented_query, n_results=n_results)

    documents = results['documents'][0]

    return documents


def _augment_query_with_example_answer(query_text: str) -> str:
    messages = [
        {"role": "system", "content": INSTRUCTIONS_EXAMPLE_ANSWER},
        {"role": "user", "content": query_text}
    ]

    hypothetical_answer = query_gpt(messages=messages)

    joint_query = f"{query_text} {hypothetical_answer}"

    return joint_query

